# Quick Reference Guide

## ğŸš€ Start the AI Stack

### Windows
```cmd
# Interactive launcher (recommended)
launch.bat

# Direct commands
scripts\start-amd.bat      # For AMD GPUs (7900 XTX)
scripts\start-nvidia.bat   # For NVIDIA GPUs
scripts\start-cpu.bat      # CPU-only mode
scripts\start-dev.bat      # Development mode (no auth)
```

### Linux/macOS
```bash
# Make scripts executable first
chmod +x scripts/*.sh launch.sh

# Interactive launcher
./launch.sh

# Direct commands
./scripts/start-amd.sh     # For AMD GPUs
./scripts/start-nvidia.sh  # For NVIDIA GPUs  
./scripts/start-cpu.sh     # CPU-only mode
```

## ğŸ›‘ Stop the AI Stack

```cmd
# Windows
scripts\stop.bat

# Linux/macOS
./scripts/stop.sh
```

## ğŸ”— Service URLs

After starting, access these services:

- **Open WebUI**: http://localhost:3000
- **ChromaDB**: http://localhost:8000  
- **n8n**: http://localhost:5678
- **Nginx Proxy Manager**: http://localhost:81
- **Ollama API**: http://localhost:11434

## ğŸ”§ Common Commands

```bash
# Check status
docker-compose ps

# View logs
docker-compose logs -f [service_name]

# Pull updates
docker-compose pull

# Restart a service
docker-compose restart [service_name]

# Download your first model
docker exec -it ollama ollama pull llama3.1

# List available models
docker exec -it ollama ollama list
```

## âš™ï¸ Configuration

Edit `.env` file to customize:
- Ports
- Passwords  
- Data paths
- GPU settings

## ğŸ©º Troubleshooting

Run health check:
```cmd
# Windows
.\health-check.bat

# Check individual service logs
docker-compose logs [service_name]
```

## ğŸ“ Project Structure

```
AI Stack/
â”œâ”€â”€ launch.bat|sh           # Interactive launcher
â”œâ”€â”€ health-check.bat        # System validation
â”œâ”€â”€ .env                    # Your configuration
â”œâ”€â”€ docker-compose.yml      # Base services
â”œâ”€â”€ docker-compose.*.yml    # Hardware profiles
â””â”€â”€ scripts/               # Start/stop scripts
```
